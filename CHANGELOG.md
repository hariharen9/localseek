# Change Log

## [0.0.5] - 2025-08-11

**Chat History**: Automatically saves your conversations for later review and continue where you left off
**Context Menu Integration**: Right-click on any code snippet and select "Send to LocalSeek Chat" to instantly send it to the chat for context-aware assistance.

## [0.0.4] - 2025-02-04

- Fixed a major bug where codeblocks fail to render properly

## [0.0.3] - 2025-02-03

- Added a new stream feature, so the AI response will be streamed without rendering at first, once completely done, then it will me MD rendered.
- This results in better stream handling and proper result render.

## [0.0.2] - 2025-02-02

### Added

- Added markdown support
- Ability to copy code directly
- Basic Ollama integration
- Chat interface in VSCode
- Model selection support
- Streaming response capabilities

## [Upcoming Features]

- Multiple conversation threads and history
- Advanced model configuration
- Local model management
- ~~Code snippet integration~~ âœ…

## [0.0.1] - 2025-02-01

### Added

- Initial release of LocalSeek
- Basic Ollama integration
- Chat interface in VSCode
- Model selection support
- Streaming response capabilities

### Known Limitations

- Limited error handling
- Basic conversation management
- Single conversation context

## [Upcoming Features]

- Multiple conversation threads
- Advanced model configuration
- Local model management
- Code snippet integration
