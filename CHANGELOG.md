# Change Log

## [0.0.3] - 2025-02-03

- Added a new stream feature, so the AI response will be streamed without rendering at first, once completely done, then it will me MD rendered.
- This results in better stream handling and proper result render.

## [0.0.2] - 2025-02-02

### Added

- Added markdown support
- Ability to copy code directly
- Basic Ollama integration
- Chat interface in VSCode
- Model selection support
- Streaming response capabilities

## [Upcoming Features]

- Multiple conversation threads and history
- Advanced model configuration
- Local model management
- ~~Code snippet integration~~ âœ…

## [0.0.1] - 2025-02-01

### Added

- Initial release of LocalSeek
- Basic Ollama integration
- Chat interface in VSCode
- Model selection support
- Streaming response capabilities

### Known Limitations

- Limited error handling
- Basic conversation management
- Single conversation context

## [Upcoming Features]

- Multiple conversation threads
- Advanced model configuration
- Local model management
- Code snippet integration
